{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8FImNBn5738O"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StNJ833n2vHN"
      },
      "source": [
        "## **Temperature Monitoring Data Analysis and Dashboard Generation | Chemonics - B&MGF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxmbJaK-pGzO",
        "outputId": "f90f3d9c-53be-4d52-e98b-a3b66c39b7b4"
      },
      "source": [
        "#@title Default title text\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y78h77zNoNBv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1YhUumioSBB"
      },
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/E4C /trucks_dataset.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7kuMUe2oiW0",
        "outputId": "89db7408-8fff-4fbf-daa0-11c3184c7988"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750281, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Y4Gdh6-KooeS",
        "outputId": "122613d5-e49f-4eb7-b9bd-b923d409e77b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>WarehouseName</th>\n",
              "      <th>Day</th>\n",
              "      <th>MonthName</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>TemperatureRange</th>\n",
              "      <th>Elapsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NTS Truck 1776 ER Back</td>\n",
              "      <td>2018-10-06 05:03:46</td>\n",
              "      <td>MZ_Maputo_NTS_White_Truck</td>\n",
              "      <td>6</td>\n",
              "      <td>October</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "      <td>30.4</td>\n",
              "      <td>30-35</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NTS Truck 1776 ER Back</td>\n",
              "      <td>2018-10-06 05:08:46</td>\n",
              "      <td>MZ_Maputo_NTS_White_Truck</td>\n",
              "      <td>6</td>\n",
              "      <td>October</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "      <td>31.1</td>\n",
              "      <td>30-35</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NTS Truck 1776 ER Back</td>\n",
              "      <td>2018-10-06 05:13:46</td>\n",
              "      <td>MZ_Maputo_NTS_White_Truck</td>\n",
              "      <td>6</td>\n",
              "      <td>October</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "      <td>32.0</td>\n",
              "      <td>30-35</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NTS Truck 1776 ER Back</td>\n",
              "      <td>2018-10-06 05:18:46</td>\n",
              "      <td>MZ_Maputo_NTS_White_Truck</td>\n",
              "      <td>6</td>\n",
              "      <td>October</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "      <td>32.4</td>\n",
              "      <td>30-35</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NTS Truck 1776 ER Back</td>\n",
              "      <td>2018-10-06 05:23:46</td>\n",
              "      <td>MZ_Maputo_NTS_White_Truck</td>\n",
              "      <td>6</td>\n",
              "      <td>October</td>\n",
              "      <td>10</td>\n",
              "      <td>2018</td>\n",
              "      <td>32.9</td>\n",
              "      <td>30-35</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Name                Date  ... TemperatureRange   Elapsed\n",
              "0  NTS Truck 1776 ER Back 2018-10-06 05:03:46  ...            30-35  0.083333\n",
              "1  NTS Truck 1776 ER Back 2018-10-06 05:08:46  ...            30-35  0.083333\n",
              "2  NTS Truck 1776 ER Back 2018-10-06 05:13:46  ...            30-35  0.083333\n",
              "3  NTS Truck 1776 ER Back 2018-10-06 05:18:46  ...            30-35  0.083333\n",
              "4  NTS Truck 1776 ER Back 2018-10-06 05:23:46  ...            30-35  0.083333\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg5Q5HatU50Q"
      },
      "source": [
        "pip install pmdarima"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Smd1_aUvny"
      },
      "source": [
        "import pmdarima as pm\n",
        "from pmdarima.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uah5k_OHVnXY"
      },
      "source": [
        "train, test = train_test_split(df, train_size=52500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD9CMNS6WRdj"
      },
      "source": [
        "df1 = df[['Date', 'Temperature']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "MiMIdlATWWZZ",
        "outputId": "953282d6-be52-4065-bd58-f92cfa5a891f"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-10-06 05:03:46</td>\n",
              "      <td>30.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-10-06 05:08:46</td>\n",
              "      <td>31.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-10-06 05:13:46</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-10-06 05:18:46</td>\n",
              "      <td>32.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-10-06 05:23:46</td>\n",
              "      <td>32.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date  Temperature\n",
              "0 2018-10-06 05:03:46         30.4\n",
              "1 2018-10-06 05:08:46         31.1\n",
              "2 2018-10-06 05:13:46         32.0\n",
              "3 2018-10-06 05:18:46         32.4\n",
              "4 2018-10-06 05:23:46         32.9"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSc4ODygXHu-",
        "outputId": "1bc200f3-dc13-487e-ae2d-bfa1a1cbbbc1"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date           0\n",
              "Temperature    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "ds_F-P4yWerL",
        "outputId": "52fd3085-d050-4772-8b0b-7febc9a835f8"
      },
      "source": [
        "train, test = train_test_split(df2, train_size=52500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5332db98571e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m52500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, *arrays)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         train_size=train_size)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2122\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         raise ValueError('train_size={0} should be either positive and smaller'\n\u001b[1;32m   1762\u001b[0m                          \u001b[0;34m' than the number of samples {1} or a float in the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                          '(0, 1) range'.format(train_size, n_samples))\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: train_size=52500 should be either positive and smaller than the number of samples 5 or a float in the (0, 1) range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "EmpjvoJaV5mu",
        "outputId": "dc980939-78f3-46d2-d4ef-14fb6f80f8d9"
      },
      "source": [
        "model = pm.auto_arima(train, seasonal=True, m=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6cb25ca289ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_arima\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/arima/auto.py\u001b[0m in \u001b[0;36mauto_arima\u001b[0;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;31m# copy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_endog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pmdarima/utils/array.py\u001b[0m in \u001b[0;36mcheck_endog\u001b[0;34m(y, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    169\u001b[0m     return column_or_1d(\n\u001b[1;32m    170\u001b[0m         check_array(y, ensure_2d=False, force_all_finite=force_all_finite,\n\u001b[0;32m--> 171\u001b[0;31m                     copy=copy, dtype=dtype))  # type: np.ndarray\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: invalid type promotion"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6u6Ed3qUdCe"
      },
      "source": [
        "Below work is previous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1005Br7YMTV"
      },
      "source": [
        "df.tail(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-EpZ2fHotrD"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQBOb3Q3phGn"
      },
      "source": [
        "df.Year.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJHsHFmNvzvW"
      },
      "source": [
        "df_new = df[df['Temperature'] < 80]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FufvaQZ1wkI6"
      },
      "source": [
        "fig = plt.figure(figsize = (20,24))\n",
        "plt.title('Temperature Distribution')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Temperature')\n",
        "plt.scatter(df_new.Date, df_new.Temperature, s=0.02,c='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6foOhT4YguA"
      },
      "source": [
        "print('this is max:', df.Temperature.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPLYpfECYy40"
      },
      "source": [
        "print('this is max:', df.Temperature.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHebHcCsxM0v"
      },
      "source": [
        "print('The first date:', df.Date.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VRvl-HVxXlZ"
      },
      "source": [
        "print('The first date:', df.Date.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZN4zuVcxjEx"
      },
      "source": [
        "for year in range(2018, 2021):\n",
        "    df_Jan = df_new[(df_new['Date'] < str(year) + '-02') & (df_new['Date'] > str(year-1) + '-12-31')]\n",
        "    fig = plt.figure(figsize = (12,8))\n",
        "    plt.title('Temperature distribution' + str(year))\n",
        "    plt.scatter(df_Jan.Date, df_Jan.Temperature, s = 0.02, c = 'r')\n",
        "    sns.kdeplot(df_Jan.Date, df_Jan.Temperature)\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Temperature')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5JveCy9BTQ"
      },
      "source": [
        "\n",
        "print(\"There should be a total of %s days\"%((pd.to_datetime('2021-01-15') - pd.to_datetime('2018-04-10')).days + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xK-PebQyj90"
      },
      "source": [
        "time_span = pd.date_range('2018-04-10', '2020-01-15')\n",
        "\n",
        "# Convert the data frame to time series data\n",
        "def df_to_TimeSeries(df):\n",
        "    date = pd.to_datetime(df.Date.value_counts().index)\n",
        "    index = sorted(date)\n",
        "    data = df.Date.value_counts().values[np.argsort(date)]\n",
        "    ts = pd.DataFrame(data = data, index = index, columns = ['count'])\n",
        "    # if a date within the time span does not exist, fill it in with count = 0\n",
        "    ts = ts.reindex(time_span, fill_value=0)\n",
        "    return ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSUhkrVz9mrQ"
      },
      "source": [
        "all_counts = df_to_TimeSeries(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nno4r_gf9r5T"
      },
      "source": [
        "# check is there is any date with count = 0\n",
        "all_counts[all_counts['count'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi0MiAM_9w3K"
      },
      "source": [
        "\n",
        "# plot the time series\n",
        "fig = plt.figure(figsize = (40, 10))\n",
        "all_counts['count'].plot()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Number of Incidents')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqMt2n_4-B7K"
      },
      "source": [
        "\n",
        "df_theft = df.loc[(df['Temperature'] == 'LARCENY/THEFT'), :]\n",
        "theft_counts = df_to_TimeSeries(df_theft)\n",
        "theft_counts[theft_counts['count'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTkHuDHf--e_"
      },
      "source": [
        "fig = plt.figure(figsize=(20,6))\n",
        "theft_counts['count'].plot()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Number of LARCENY/THEFT Incidents')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6pTP3tw_JJ5"
      },
      "source": [
        "df_assault = df.loc[(df['Temperature'] == 'Date'), :]\n",
        "assault_counts = df_to_TimeSeries(df_assault)\n",
        "assault_counts[assault_counts['count'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhvKpn4M_SUd"
      },
      "source": [
        "fig = plt.figure(figsize=(20,6))\n",
        "assault_counts['count'].plot()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('MV')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0lnBAwW_vES"
      },
      "source": [
        "y = theft_counts.resample('MS').sum()\n",
        "y.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5NbBs2NAwpp"
      },
      "source": [
        "y = y[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnBmtLUxA2CX"
      },
      "source": [
        "fig = plt.figure(figsize=(20,6))\n",
        "y['count'].plot()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('MV')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy_O4RUnA7UY"
      },
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Vc9PBCBgwj"
      },
      "source": [
        "y_past, y_future = y[:-12], y[-12:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86wdIdxrBinc"
      },
      "source": [
        "import itertools\n",
        "p = d = q = range(0, 2)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVuWUhXuBoqS"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "aic_min = float(\"inf\")\n",
        "param = (0,0,0,0,0,0)\n",
        "best_model = None\n",
        "\n",
        "for x1 in pdq:\n",
        "    for x2 in seasonal_pdq:\n",
        "        try:\n",
        "            mod = SARIMAX(y_past,\n",
        "                          order = x1,\n",
        "                          seasonal_order = x2,\n",
        "                          enforce_stationarity = False,\n",
        "                          enforce_invertibility = False)\n",
        "            results = mod.fit()\n",
        "            print(\"(p,d,q,P,D,Q,S) = {}: AIC = {}\".format(x1 + x2, results.aic))\n",
        "            if results.aic < aic_min:\n",
        "                aic_min = results.aic\n",
        "                param = x1 + x2\n",
        "                best_model = mod\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3HvTfihBwZa"
      },
      "source": [
        "print(\"Best (p,d,q,P,D,Q,S) =\", param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPcO7p0YB5Vx"
      },
      "source": [
        "results = best_model.fit()\n",
        "results.summary().tables[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoSSm5gmTrqf"
      },
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "result = adfuller(y['count'].values[1:])\n",
        "print(\"-- Before taking the difference --\")\n",
        "print (\"ADF Statistic:\", result[0])\n",
        "print (\"p-value:\", result[1])\n",
        "\n",
        "diff = y.diff()\n",
        "result = adfuller(diff['count'].values[1:])\n",
        "print (\"-- After taking the difference --\")\n",
        "print (\"ADF Statistic:\", result[0])\n",
        "print (\"p-value:\", result[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k69yEPwTuiB"
      },
      "source": [
        "# neglect the beginning of the time series, where the model hasn't converged\n",
        "pred = results.get_prediction(start = y_past['2018-06':].index[0],  dynamic=False)\n",
        "pred_ci = pred.conf_int() # 95% confidence interval \n",
        "\n",
        "forecast = results.get_forecast(steps=28) # forecast for the next 12 months\n",
        "forecast_ci = forecast.conf_int() # 95% confidence interval \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 16))\n",
        "\n",
        "ax.plot(y['2018-06':].index, y['2018-06':], label='Observed', color='b')\n",
        "\n",
        "pred.predicted_mean.plot(ax=ax, label='In-sample Prediction', color='k')\n",
        "ax.fill_between(pred_ci.index,\n",
        "                pred_ci.iloc[:, 0],\n",
        "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
        "\n",
        "forecast.predicted_mean.plot(ax=ax, label='Out-of-sample Forecast', color='r')\n",
        "ax.fill_between(forecast_ci.index,\n",
        "                forecast_ci.iloc[:, 0],\n",
        "                forecast_ci.iloc[:, 1], color='r', alpha=.2)\n",
        "\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('Std')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q17Gl_L8U0J9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-MKLnEdCD8y"
      },
      "source": [
        "results.plot_diagnostics(figsize=(16, 12))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4h99jScBAYC"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = 11, 9\n",
        "decomposition = seasonal_decompose(y, model='additive')\n",
        "decomposition.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKsnK8FAJwax"
      },
      "source": [
        "Adf =df.sort_values(\"Year\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIwyAAaZJ1Zt"
      },
      "source": [
        "Adf = df[['Year', 'Temperature']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-m8dhLKKAhH"
      },
      "source": [
        "Adf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRBofgmuKEON"
      },
      "source": [
        "Adf1 = Adf.rename(columns={'Year':'ds', 'Temperature':'y'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_kkNI8mKWKA"
      },
      "source": [
        "Adf1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdejpoNDR3uz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7M87h_VRuOT"
      },
      "source": [
        "Adf1.plot(figsize=(16, 12))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHkDthDxSTKv"
      },
      "source": [
        "fig = Adf1.plot(figsize=(16, 12))\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oicRZDGALEgK"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Check for Facebook Prophet\n",
        "# if not exists then install; takes ~3 minutes\n",
        "try:\n",
        "  from fbprophet import Prophet\n",
        "except ImportError:\n",
        "  !pip install pystan\n",
        "  !pip install fbprophet\n",
        "  from fbprophet import Prophet\n",
        "  from IPython import display\n",
        "  display.clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGbhi90uLG0u"
      },
      "source": [
        " !pip install pystan\n",
        " !pip install fbprophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi36XFkRMKAg"
      },
      "source": [
        "# defining the number of observations we want to predict\n",
        "nobs = 36\n",
        "train = Adf1[:-nobs]\n",
        "test = Adf1[-nobs:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6lFWgVwMt6a"
      },
      "source": [
        "print(f\"Length of dataframe: {len(Adf1)}\\n\"\n",
        "      f\"Length of train set: {len(train)}\\n\"\n",
        "      f\"Length of test set: {len(test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT1mL6ruOM6H"
      },
      "source": [
        "# Creating an instance of the Prophet model\n",
        "prophet = Prophet()\n",
        "# fitting Prophet model to the train set\n",
        "prophet.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVz3bpanOXNa"
      },
      "source": [
        "future = prophet.make_future_dataframe(periods=nobs, freq='MS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tea9n_CHObfg"
      },
      "source": [
        "forecast = prophet.predict(future)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLsQgJkkOfwU"
      },
      "source": [
        "forecast.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThAgvOaPOoRS"
      },
      "source": [
        "fig1 = prophet.plot(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLZlwJkOO_3a"
      },
      "source": [
        "prophet.plot(forecast)\n",
        "ax=forecast.plot(x='ds',y='yhat',legend=True,label='predictions',figsize=(12,8))\n",
        "test.plot(x='ds',y='y',legend=True,label='True Test Data',ax=ax,xlim=('2018-09-01','2020-12-01'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTBX-I0aPhGl"
      },
      "source": [
        "from statsmodels.tools.eval_measures import rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9jvRFcfPMQP"
      },
      "source": [
        "# Remember nobs = 12\n",
        "y_pred = forecast.iloc[-nobs:]['yhat']\n",
        "y_true = test['y']\n",
        "rmse(y_pred, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biq2h3IBPkod"
      },
      "source": [
        "# changing trend points\n",
        "from fbprophet.plot import add_changepoints_to_plot\n",
        "fig=prophet.plot(forecast)\n",
        "a=add_changepoints_to_plot(fig.gca(), prophet, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYqJvqzLLyjl"
      },
      "source": [
        "Adf1[‘ds’] = pd.to_datetime(Adf1[‘ds’])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzcjjmGzKtzO"
      },
      "source": [
        "from cuml.tsa.arima import ARIMA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2T1_ZaTKZ-G"
      },
      "source": [
        "model_temp = ARIMA(Adf1, order=(1,2,1), fit_intercept=True)\n",
        "model_temp.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adi4WDuT_gp_"
      },
      "source": [
        "y = theft_counts.resample('Date').sum()\n",
        "y.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOUD7wIQrCqq"
      },
      "source": [
        "# datatime conversion\n",
        "# Convert \"Date\" into a from of \"yyyy-mm-dd\" and create another column \"Month\" for later use\n",
        "df.Date = df.Date.map(lambda x: x.split('/')[2] + '-' + x.split('/')[0] + '-' + x.split('/')[1])\n",
        "df['Month'] = df.Date.map(lambda x: int(x.split('-')[1]))\n",
        "\n",
        "# Count the number of incidents for each month\n",
        "monthly_count = df.Month.value_counts()\n",
        "monthly_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKSPQuDQqEs6"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.bar(sorted(monthly_count.index), monthly_count.values[np.argsort(monthly_count.index)])\n",
        "plt.xlabel(\"MonthName\")\n",
        "plt.ylabel(\"Temperature\")\n",
        "plt.xlim((0.5,12.5))\n",
        "plt.ylim((150000,220000))\n",
        "plt.xticks(np.arange(1, 13))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thBXIkYdkjvD"
      },
      "source": [
        "pip install rapids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIrNDEqvmn_c"
      },
      "source": [
        "pip install conda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQiW-3gnnXn"
      },
      "source": [
        "!pip install 'cudatoolkit=10.1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff4Ioi-Fk97O"
      },
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/env-check.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGy9_Pfho7xw"
      },
      "source": [
        "# This will update the Colab environment and restart the kernel.  Don't run the next cell until you see the session crash.\n",
        "!bash rapidsai-csp-utils/colab/update_gcc.sh\n",
        "import os\n",
        "os._exit(00)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN99fDmfpUqR"
      },
      "source": [
        "# This will install CondaColab.  This will restart your kernel one last time.  Run this cell by itself and only run the next cell once you see the session crash.\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTZ2MAw1pkvz"
      },
      "source": [
        "# you can now run the rest of the cells as normal\n",
        "import condacolab\n",
        "condacolab.check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hkp9PpcppFI"
      },
      "source": [
        "# Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
        "# The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
        "# The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL, \n",
        "!python rapidsai-csp-utils/colab/install_rapids.py stable\n",
        "import os\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feP6glsyqGFs"
      },
      "source": [
        "import cudf\n",
        "import io, requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QW3CysGqH05"
      },
      "source": [
        "import cuml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvj1b7inutdb"
      },
      "source": [
        "from cuml.tsa.arima import ARIMA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GIoTpBBA9NM"
      },
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import datetime\n",
        "import pandas as p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Krdu1d1vd2M"
      },
      "source": [
        "A simple MA(2) example\n",
        "We start with a simple Moving Average model. Let's first load and visualize the migrations in Auckland by age dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnqf1524uLZT"
      },
      "source": [
        "df_mig = pd.read_excel(\"/content/drive/MyDrive/E4C /Test set.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St1C_MGov__x"
      },
      "source": [
        "df_mig.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sckBakLvazV"
      },
      "source": [
        "We want to fit the model with q=2 and with an intercept. The ARIMA class accepts cuDF dataframes or array-like types as input (host or device), e.g numpy arrays. Here we already have a dataframe so we can simply pass it to the ARIMA constructor with the model parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1zwM7D6xFHI"
      },
      "source": [
        "Adf =df_mig.sort_values(\"Year\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W9qaaR1xUBY"
      },
      "source": [
        "Adf = df_mig[['Year', 'Temperature']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpdp3JXZxiWg"
      },
      "source": [
        "Adf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5N2ywInyGOj"
      },
      "source": [
        "Adf1 = Adf.rename(columns={'Year':'ds', 'Temperature':'y'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7bwicApyNaQ"
      },
      "source": [
        "Adf1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eU2AQj4vYzo"
      },
      "source": [
        "model_temp = ARIMA(Adf1, order=(1,2,1), fit_intercept=True)\n",
        "model_temp.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F7EGozmJcY6"
      },
      "source": [
        "# Predict in-sample and forecast out-of-sample\n",
        "pred_temp = model_temp.predict(80, 160)\n",
        "visualize(Adf1, pred_temp, 80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxhhSUubPi2H"
      },
      "source": [
        "Confidence intervals\n",
        "To get confidence intervals when forecasting, we can specify the confidence level (here 95%):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUHJ2GXqParA"
      },
      "source": [
        "fc_temp, lower_temp, upper_temp = model_temp.forecast(23, level=0.95)\n",
        "visualize(Adf1, fc_temp, lower=lower_temp, upper=upper_temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amw6jtO4P3XJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdY-RobEKLb6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpKu6mF7iqwG"
      },
      "source": [
        "from fbprophet import Prophet\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KdNqSp49YrO"
      },
      "source": [
        "df1 = pd.read_excel(\"/content/drive/MyDrive/E4C /trucks_dataset.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VK8m0bZ9ghZ"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDmB5YwMKp4F"
      },
      "source": [
        "data = pd.read_excel(\"/content/drive/MyDrive/E4C /trucks_datasetCC.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVOPk57eK3Vs"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osxzl4_E01q8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBjgzyyD0jKq"
      },
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2RVP1zM070T"
      },
      "source": [
        "data.index = pd.to_datetime(data['Temperature'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn_grSou2NuJ"
      },
      "source": [
        "rolling_mean = data.rolling(window = 12).mean()\n",
        "data['rolling_mean_diff'] = rolling_mean - rolling_mean.shift()\n",
        "ax1 = plt.subplot()\n",
        "data['rolling_mean_diff'].plot(title='after rolling mean & differencing');\n",
        "ax2 = plt.subplot()\n",
        "data.plot(title='original');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Unv1Ii1YGH"
      },
      "source": [
        "seasonality=data.seasonal\n",
        "seasonality.plot(color='green')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQg-dJg-yrtO"
      },
      "source": [
        "# Filter data\n",
        "df = df[df['Temperature']==country]\n",
        "df.rename(columns={\"date\": \"ds\", filter_case: \"y\"},inplace=True) \n",
        "df['ds'] = pd.to_datetime(df['ds'],infer_datetime_format=True)\n",
        "df = df[df['ds']>\"2020-02-01\"]\n",
        "df['y'] = df['y'].astype(float)\n",
        "df = df[['y','ds']]\n",
        "\n",
        "# Run Prophet to get predictions\n",
        "pred = Prophet()\n",
        "pred.fit(df)\n",
        "future = pred.make_future_dataframe(periods=365)\n",
        "forecast = pred.predict(future)\n",
        "\n",
        "#Plot the prediction Graph\n",
        "graph = pred.plot(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hu2KJHkyNN9"
      },
      "source": [
        "from sktime.forecasting.arima import AutoARIMA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWioKPNyHII"
      },
      "source": [
        "from sktime.forecasting.arima import AutoARIMA\n",
        "\n",
        "forecaster = AutoARIMA(start_p=8, max_p=9, suppress_warnings=True)\n",
        "sun_train.index = sun_train.index.astype(int)\n",
        "forecaster.fit(sun_train)\n",
        "forecaster.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eVESDfPu-MN"
      },
      "source": [
        "# Run the ADF test on the time series\n",
        "result = adfuller(df['Temperature'])\n",
        "\n",
        "# Plot the time series\n",
        "fig, ax = plt.subplots();\n",
        "city.plot(ax=ax);\n",
        "\n",
        "# Print the test statistic and the p-value\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D63XnSdVpVUF"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Check for Facebook Prophet\n",
        "# if not exists then install; takes ~3 minutes\n",
        "try:\n",
        "  from fbprophet import Prophet\n",
        "except ImportError:\n",
        "  !pip install pystan\n",
        "  !pip install fbprophet\n",
        "  from fbprophet import Prophet\n",
        "  from IPython import display\n",
        "  display.clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BtvUBp0pYEt"
      },
      "source": [
        "!pip install pystan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrfPhCgKphkE"
      },
      "source": [
        " !pip install pystan\n",
        " !pip install fbprophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLMpM4GPp0pM"
      },
      "source": [
        "df = df.sort_values(\"Date\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCix_i1lrV4d"
      },
      "source": [
        "Temp_prophet_df = df[['Date', 'Temperature']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd7hZoGTrsH-"
      },
      "source": [
        "Temp_prophet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjuOE4KMr3MY"
      },
      "source": [
        "Temp_prophet_df = Temp_prophet_df.rename(columns={'Date':'ds', 'Temperature':'y'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgmychy0sLnd"
      },
      "source": [
        "Temp_prophet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_mLBAh-jt_0"
      },
      "source": [
        "Temp_prophet_df[‘ds’] = pd.to_datetime(Temp_prophet_df[‘ds’])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_CuZfT-kE8U"
      },
      "source": [
        "# defining the number of observations we want to predict\n",
        "nobs = 12\n",
        "train = Temp_prophet_df[:-nobs]\n",
        "test = Temp_prophet_df[-nobs:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QARXHTEKkKq_"
      },
      "source": [
        "print(f\"Length of dataframe: {len(Temp_prophet_df)}\\n\"\n",
        "      f\"Length of train set: {len(train)}\\n\"\n",
        "      f\"Length of test set: {len(test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK5oxJHtkOcw"
      },
      "source": [
        "# Creating an instance of the Prophet model\n",
        "prophet = Prophet()\n",
        "# fitting Prophet model to the train set\n",
        "prophet.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kenQU0T1k8PC"
      },
      "source": [
        "future = prophet.make_future_dataframe(periods=nobs, freq='MS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16KkTshdlRhp"
      },
      "source": [
        "forecast = prophet.predict(future)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUAR0NovnCsU"
      },
      "source": [
        "forecast.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13fwekvYqN-h"
      },
      "source": [
        "From the Table above,\n",
        "Trend:  \n",
        "**yhat:** the forecasted value of our metric (in Statistics, yhat is a notation \n",
        "traditionally used to represent the predicted values of a value y)\n",
        "**yhat_lower:** the lower bound of our forecasts\n",
        "**yhat_upper:** the upper bound of our forecasts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ5jd9YbvUKn"
      },
      "source": [
        "pred[['ds', 'trend', 'yhat', 'yhat_upper', 'yhat_lower']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPRpKaCUlW1R"
      },
      "source": [
        "fig1 = prophet.plot(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU9nrMqHnwJB"
      },
      "source": [
        "From the plot above, Prophet plots the observed values of time series(black dots),the forecasted values(blue lines) and the uncertainty intervals of our forecasts(blue shaded region). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei870MKMzBbk"
      },
      "source": [
        "df = Temp_prophet_df[Temp_prophet_df['Temperature']]\n",
        "df.rename(columns={\"date\": \"ds\", filter_case: \"y\"},inplace=True) \n",
        "df['ds'] = pd.to_datetime(df['ds'],infer_datetime_format=True)\n",
        "df = df[df['ds']>\"2020-02-01\"]\n",
        "df['y'] = df['y'].astype(float)\n",
        "df = df[['y','ds']]\n",
        "\n",
        "# Run Prophet to get predictions\n",
        "pred = Prophet()\n",
        "pred.fit(df)\n",
        "future = pred.make_future_dataframe(periods=365)\n",
        "forecast = pred.predict(future)\n",
        "\n",
        "#Plot the prediction Graph\n",
        "graph = pred.plot(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY8vcqL-ohBI"
      },
      "source": [
        "prophet.plot(forecast)\n",
        "ax=forecast.plot(x='ds',y='yhat',legend=True,label='predictions',figsize=(12,8))\n",
        "test.plot(x='ds',y='y',legend=True,label='True Test Data',ax=ax,xlim=('2018-09-01','2020-12-01'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfGo9pOHq_Yu"
      },
      "source": [
        "As you can see from the above plot predictions and test values are almost going together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cajpdXoorBuw"
      },
      "source": [
        "** Returning components** of our forecasts.This can help reveal how daily, weekly and yearly patterns of the time series contribute to the overall forecasted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1yusNQSrUC6"
      },
      "source": [
        "fig=prophet.plot_components(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbnxn0Dhrryv"
      },
      "source": [
        "Since we are working with daily data, you would see a weekly seasonality plot "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU1O3kWAtNQk"
      },
      "source": [
        "Great - But how do we know if our model actually performed well? We can import a root-mean-square error function from the statsmodels library to compare the RMSE of our predictions to the true values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yMc5D-gs6nW"
      },
      "source": [
        "from statsmodels.tools.eval_measures import rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQQh6sYQtXvC"
      },
      "source": [
        "To make sure that we feed in the correct variable to the prediction parameter, we will create a new variable called ‘y_pred’. Remember that the forecast variable contains more than the final 12 rows that are our predictions, so we need to separate our prediction values and specify the ‘yhat’ column to make sure our ‘y_pred’ variable is a reference to an array containing the 12-month predictions. We can also define ‘y_true’ to make it look nicer when using the RMSE function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodVKByYs82z"
      },
      "source": [
        "# Remember nobs = 12\n",
        "y_pred = forecast.iloc[-nobs:]['yhat']\n",
        "y_true = test['y']\n",
        "rmse(y_pred, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YddLZ3xytxfS"
      },
      "source": [
        "Chainging points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82sRt8Rmtvw4"
      },
      "source": [
        "# changing trend points\n",
        "from fbprophet.plot import add_changepoints_to_plot\n",
        "fig=prophet.plot(forecast)\n",
        "a=add_changepoints_to_plot(fig.gca(), prophet, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGyy7QBuHIL"
      },
      "source": [
        "These red dotted line show the major points where trendline happens to change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lniRLxEuKOU"
      },
      "source": [
        "**Valadation **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0H8gnwmr1Ft"
      },
      "source": [
        "# Initial training period.\n",
        "initial= 2*50\n",
        "initial= str(initial)+' days'\n",
        "#Period length that we perform the cross validation for.\n",
        "period= 2*365\n",
        "period=str(period)+' days'\n",
        "#Horizon of prediction essentially for each fold.\n",
        "horizon = 365\n",
        "horizon=str(horizon)+' days'\n",
        "fb_cv= cross_validation(prophet, initial=initial, period=period, horizon=horizon)\n",
        "# Performance Metrics of fb_cv\n",
        "performance_metrics(fb_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MslaLInmAjD"
      },
      "source": [
        "!pip install pystan\n",
        "!pip install fbprophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9iuEH1JmpmL"
      },
      "source": [
        "from fbprophet import Prophet\n",
        "from fbprophet.diagnostics import cross_validation\n",
        "from fbprophet.diagnostics import performance_metrics\n",
        "from fbprophet.plot import plot_cross_validation_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG0IlT3vluj1"
      },
      "source": [
        "from fbprophet.plot import add_changepoint_to_plot\n",
        "fig1 = prophet.plot(forecast)\n",
        "# viewing the points in time where the trajectory of the price index changed\n",
        "a = add_changepoints_to_plot(fig1.gca(), prophet, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HubHoETsNdH"
      },
      "source": [
        "m = Prophet()\n",
        "m.fit(Temp_prophet_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_KdjN7Xsemy"
      },
      "source": [
        "# Forcasting into the future\n",
        "future = m.make_future_dataframe(periods=1825)\n",
        "forecast = m.predict(future)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l5fhGNhsjPJ"
      },
      "source": [
        "forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrPT1VTY7Ky6"
      },
      "source": [
        "Y hat (written ŷ ) is the predicted value of y (the dependent variable) in a regression equation. It can also be considered to be the average value of the response variable. ... The equation is calculated during regression analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRjCr_A7sYBy"
      },
      "source": [
        "figure = m.plot(forecast, xlabel='Date', ylabel='Temperature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f1ufq45qL1Y"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(df['Date'], df['Temperature'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1M3AgK17TP2"
      },
      "source": [
        "figure3 = m.plot_components(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LdG3HUhKjoQ"
      },
      "source": [
        "import numpy as np\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 70)\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "py.init_notebook_mode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjmO8-gfKHKv"
      },
      "source": [
        "py.iplot([\n",
        "    go.Scatter(x=Temp_prophet_df['ds'], y=Temp_prophet_df['y'], name='y'),\n",
        "    go.Scatter(x=forecast['ds'], y=forecast['yhat'], name='yhat'),\n",
        "    go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], fill='tonexty', mode='none', name='upper'),\n",
        "    go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], fill='tonexty', mode='none', name='lower'),\n",
        "    go.Scatter(x=forecast['ds'], y=forecast['trend'], name='Trend')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOY1oPfqLQEc"
      },
      "source": [
        "print('RMSE: %f' % np.sqrt(np.mean((forecast.loc[:1825, 'yhat']-Temp_prophet_df['y'])**2)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t2S8hjCLoPJ"
      },
      "source": [
        "m = Prophet(changepoint_prior_scale=2.5)\n",
        "m.fit(Temp_prophet_df)\n",
        "future = m.make_future_dataframe(periods=365)\n",
        "forecast = m.predict(future)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE8NX9A5MNj0"
      },
      "source": [
        "figure4 = m.plot(forecast, xlabel='Date', ylabel='Temperature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCkmOEHM8cH"
      },
      "source": [
        "print('RMSE: %f' % np.sqrt(np.mean((forecast.loc[:1825, 'yhat']-Temp_prophet_df['y'])**2)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4MNNAWOhqI"
      },
      "source": [
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from fbprophet import Prophet\n",
        "\n",
        "# TODO: linear regression for future predictions\n",
        "from sklearn import linear_model\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtsUgrQ8OubI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwOH-d3O7w_5"
      },
      "source": [
        "# dataframes creation for both training and testing datasets part2\n",
        "Temp_prophet_df = pd.read_csv('/content/drive/MyDrive/E4C /Samplecsvdatafile1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RljnAJfX78HR"
      },
      "source": [
        "Temp_prophet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhX2rUxx8Awg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVYGWnKI6Zl1"
      },
      "source": [
        "# Bar Chart to indicate the number of regions \n",
        "plt.figure(figsize=[25,12])\n",
        "sns.countplot(x = 'Date', data =Temp_prophet_df)\n",
        "plt.xticks(rotation = 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt3kmfq7UOle"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzqcU0Xcg8RG"
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "indexDaset = df.set_index(['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY5R2171iIIb"
      },
      "source": [
        "from datetime import datetime\n",
        "indexDaset.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpiRZwoyiZ83"
      },
      "source": [
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Temperature\")\n",
        "plt.plot(indexedDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfreDrYpe66Z"
      },
      "source": [
        "cols_plot = ['Date', 'Year', 'Temperature']\n",
        "\n",
        "axes = time_series_df[cols_plot].plot(marker='.', alpha=0.5, linestyle='None', subplots=True)\n",
        "for ax in axes:\n",
        "    ax.set_ylabel('Temperature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDlQUHK_UQum"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/E4C /Mo.txt\")\n",
        "display(df.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msa3-0UsUbyp"
      },
      "source": [
        "print(\"Number of rows: \", df.shape[0])\n",
        "counts = df.describe().iloc[0]\n",
        "display(\n",
        "pd.DataFrame(\n",
        "counts.tolist(), \n",
        "columns=[\"Count of values\"], \n",
        "index=counts.index.values\n",
        ").transpose()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJjLwkZpUlxC"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G8ZFk1iV_sn"
      },
      "source": [
        "numerical_feature = [feature for feature in df.columns if df[feature].dtypes!=\"O\"]\n",
        "numerical_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IuIArOaGsTV"
      },
      "source": [
        "This is a Bioinformatics Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_aaFojyGrPW"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpd7EA9UrQP"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=30)\n",
        "clf.fit(df_train, df_train[\"Temperature\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqZqg1sANKnd"
      },
      "source": [
        "to remove all the columns that are unusable from the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxzBN0FyNDc_"
      },
      "source": [
        "numerical_feature = [feature for feature in df.columns if df[feature].dtypes!=\"O\"]\n",
        "numerical_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCkLK2TYNSQH"
      },
      "source": [
        "for feature in numerical_feature:\n",
        "   sns.scatterplot(x = df[feature], y = df['Temperature'])\n",
        "   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUqiLag5Ni_Y"
      },
      "source": [
        "df = df.drop(['Name', 'Date', 'MonthName'], axis=1)\n",
        "df['Temperature'] = np.log(df['Temperature'])\n",
        "scaler=MinMaxScaler()\n",
        "scaler.fit(df)\n",
        "dataset=pd.DataFrame(scaler.transform(df),columns=df.columns)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itCB8mWUO5Bw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SltEB2gsOckK"
      },
      "source": [
        "X=df.drop(['Temperature'], axis=1)\n",
        "y=df['Temperature']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xDwzPCyOo4E"
      },
      "source": [
        "lr=LinearRegression()\n",
        "lr.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwWXhHlaN6Fv"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16TIhEHlN1UW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFB_FB8UK6oL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3pm-2dGrhSb"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUtRgzLYr0nH"
      },
      "source": [
        "%cd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buq1ZEGir30y"
      },
      "source": [
        "%cd /content/drive/MyDrive/E4C /Mo.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXIU5PFDk7K0"
      },
      "source": [
        "#Adding necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngmemK_Lr81F"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/E4C /Mo.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsemsrFzsK2t"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTkzPgpXkn6B"
      },
      "source": [
        "df1 = df.drop([\"Name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFOYZiQimtE"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ynOB2q4iuXN"
      },
      "source": [
        "plt.hist(df[\"Temperature\"], bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5hd8wHzjOhe"
      },
      "source": [
        "!pip install sklearn # ! says to run in terminal\n",
        "from sklearn.linear_model import LinearRegression # import the linear regression model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MOBxRhjjf9R"
      },
      "source": [
        "X_test = pd.read_csv(\"/content/drive/MyDrive/E4C /Mo.txt\") # load in the separate testing data\n",
        "\n",
        "y_test = X_test[\"Temperature\"] # set our output equal to the median house value column\n",
        "X_test = X_test.drop([\"Temperature\"], axis = 1) # remove that column from the input. axis = 1 means to remove the column\n",
        "\n",
        "y_train = df[\"Temperature\"] # same thing for training data\n",
        "X_train = df.drop([\"Temperature\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTXB0ckkD2G"
      },
      "source": [
        "lm = LinearRegression().fit(X_train, y_train) # .fit() fits the data to the model\n",
        "y_pred = lm.predict(X_test) # test how accurate the model is using testing data\n",
        "\n",
        "print(\"R-Squared value:\",lm.score(X_test,y_test)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFOuAK4hwXcL"
      },
      "source": [
        "df.tail(700)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUcUP6P_cKMC"
      },
      "source": [
        "In [1]: import pandas as pd\n",
        "   ...: import numpy as np\n",
        "   ...: \n",
        "   ...: from bcpandas import SqlCreds, to_sql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tikP86fwccb4"
      },
      "source": [
        "pip install bcpandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-LPtcXxcnvG"
      },
      "source": [
        "In [1]: import pandas as pd\n",
        "   ...: import numpy as np\n",
        "   ...: \n",
        "   ...: from bcpandas import SqlCreds, to_sql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5qSW-ercqf8"
      },
      "source": [
        "In [2]: creds = SqlCreds(\n",
        "   ...:     'temperaturemonitoringserver.database.windows.net',\n",
        "   ...:     'TemperatureMonitoringDB',\n",
        "   ...:     'Admin123',\n",
        "   ...:     'Password123'\n",
        "   ...: )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtuWj9LMdZS3"
      },
      "source": [
        "df = pd.DataFrame(\n",
        "   ...:         data=np.ndarray(shape=(30, 4), dtype=int), \n",
        "   ...:         columns=[f\"col_{x}\" for x in range(4)]\n",
        "   ...:     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnsfAtJwdoi3"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPJOos_SfLSE"
      },
      "source": [
        "#Adding necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHBwLaqafS9V"
      },
      "source": [
        "display(df.dtypes) #To find the type of attribute of each column\n",
        "df.shape #To find the number of rows and columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRoohGCleDzS"
      },
      "source": [
        "to_sql(df, 'my_test_table', creds, index=False, if_exists='replace')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj9DnIpS5WvK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0r8LdEomtQs"
      },
      "source": [
        "!unzip /content/drive/MyDrive/ETALO/TemperatureMonitoringDB202108210213.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j315il4VRxTQ"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH959yRFTF5u"
      },
      "source": [
        "!unzip /content/TemperatureMonitoringDB202108210213.bacpac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utl628RHCTnn"
      },
      "source": [
        "%cd /content/TemperatureMonitoringDB202108210213.bacpac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmgwy3CmTuwb"
      },
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as et\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWO8Jnw7Txzd"
      },
      "source": [
        "with os.scandir('/content/Data/dbo.Warehouse_table') as entries:\n",
        "    for entry in entries:\n",
        "        print(entry.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi-i4nXOC-iZ"
      },
      "source": [
        "%cd /content/Data/dbo.Warehouse_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdIIGoKNDFpD"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-naVy1uMeXT"
      },
      "source": [
        "pip install bcpandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuuSp6iEa_q"
      },
      "source": [
        "#!/bin/bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWzidPxMDRBl"
      },
      "source": [
        "df = pd.read_bcp('TableData-013-00001.BCP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5CSu2OtLgfl"
      },
      "source": [
        "!df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8rnOaEgDttV"
      },
      "source": [
        "df=pd.read_sql_query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zVGSvPRbWxL"
      },
      "source": [
        "df = pd.read_sql_table('/content/Data/dbo.Warehouse_table/TableData-002-00001.BCP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z_oPFtbbEXk"
      },
      "source": [
        "df = pd.read_table('Data/dbo.Warehouse_table/TableData-034-00002.BCP ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMxxke5jUl1q"
      },
      "source": [
        "with os.scandir('/content/Data/dbo.Sensor_Warehouse') as entries:\n",
        "    for entry in entries:\n",
        "        print(entry.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7jGE5jfUxuC"
      },
      "source": [
        "with os.scandir('/content/Data/dbo.Master_key') as entries:\n",
        "    for entry in entries:\n",
        "        print(entry.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2Qy6jAWO5-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXLkvq9wXTnX"
      },
      "source": [
        "df = pd.read_csv('/content/Data/dbo.Warehouse_table/TableData-002-00001.BCP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inEpDqDKWMgq"
      },
      "source": [
        "path = \"/content/Data/dbo.Warehouse_table\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhlEck5W4Vx"
      },
      "source": [
        "df_bonus = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMuNUDYJKtt8"
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVUk3Tg4K0Qx"
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_X9jACEMOcE"
      },
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "#!ls \"/gdrive/My Drive/folder\"\n",
        "#!ls \"/gdrive/My Drive/folder\"\n",
        "\n",
        "files = glob.glob(f\"/content/drive/MyDrive/chem*.txt\")\n",
        "for file in files:  \n",
        "  do_something(file)*.txt\")\n",
        "for file in files:  \n",
        "  do_something(file)*.txt\")\n",
        "for file in files:  \n",
        "  do_something(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65wU5Zfx3oHS"
      },
      "source": [
        "### **I. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NopQA68xKkef"
      },
      "source": [
        "#Adding necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqBcLpnOZRN"
      },
      "source": [
        "copied_path = ‘/content/drive/MyDrive/ETALO/TemperatureMonitoringDB202108210213.zip’ #remove ‘content/’ from path then use \n",
        "data = pd.read_csv(drive/MyDrive/chem/TableData-000-00001.BCP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVpJCVnRZ6v2"
      },
      "source": [
        "#Reading the file and display first rows\n",
        "df = pd.read_csv(/content/drive/MyDrive/chem/TableData-000-00001.BCP)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6sw1aVtaU8c"
      },
      "source": [
        "#Display the bottom rows\n",
        "df.tail(5)                        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLI0g130erKA"
      },
      "source": [
        "from scipy import stats\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7KF2CzKevpR"
      },
      "source": [
        "t_test(df, \"Temperature\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHBolOrMaley"
      },
      "source": [
        "Viewing the data from the tail end, it shows that the column for the Total Hourly Rain and Maximum Hourly rainfall rate have entries (0) yet it is null from the view of the head side."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmxbaoM9bLWr"
      },
      "source": [
        " Checking the types of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_2mPzaoeu0J"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2TyMgc3bOdZ"
      },
      "source": [
        "display(df.dtypes) #To find the type of attribute of each column\n",
        "df.shape #To find the number of rows and columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9AGej5Wv2R3"
      },
      "source": [
        "#Checking if there are any duplicated rows\n",
        "duplicate_rows_df = df[df.duplicated()]\n",
        "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lash7VwNwJem"
      },
      "source": [
        "There are no duplicated rows "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL3UCZKXwOPr"
      },
      "source": [
        "df.count() #To find values different from null on each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogAGbtETCgNp"
      },
      "source": [
        "Find number of nulls on each columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECccFf3Mxd8z"
      },
      "source": [
        "#Find number of nulls on each columns. Two attributes have 228 null values\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBeTpbhVeyH"
      },
      "source": [
        "df[\"Temperature\"].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKFW4o-cf2B"
      },
      "source": [
        "df[\"Temperature\"].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cww9XVcNUsDD"
      },
      "source": [
        "rng = np.random.RandomState(42)\n",
        "ser = pd.Series(rng.rand(5))\n",
        "ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGg98kVmfeJQ"
      },
      "source": [
        "df.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlb32qN4AhRx"
      },
      "source": [
        "#Presenting the distribution of each attribute from the dataset using histograms\n",
        "df.hist(column = 'Temp', figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Ses4ks_mh8"
      },
      "source": [
        "df.hist(column = 'Rh', figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8vCjyhIxbIM"
      },
      "source": [
        "Detecting missing or null values in the attributes 'Total Hourly Rain' and 'Time of Rainfall'. The distribution of those values is no normal, with high frequency in just one value. Included in the dropped columns along with the categorical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSDl7_EHCksc"
      },
      "source": [
        "\n",
        "#Dropping categorical columns to obtain the final dataset\n",
        "num_df = df.drop(['Serial_id'], axis=1)\n",
        "num_df['Temp'] = num_df['Temp']*(10**-2)\n",
        "num_df['Rh'] = num_df['Rh']*(10**-1)\n",
        "num_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYDkMkw6mz8E"
      },
      "source": [
        "#We describe the dataset to find the mean, the standard deviation, and the maximum and minimum values for each attribute\n",
        "num_df.describe(datetime_is_numeric=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uTiav8Dx1--"
      },
      "source": [
        "Detecting Outliers\n",
        "\n",
        "An outlier is a point or set of points that are different from other points. Sometimes they can be very high or very low. It's often a good idea to detect and remove the outliers. Because outliers are one of the primary reasons for resulting in a less accurate model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMhzo6r9zLZ-"
      },
      "source": [
        "#Importing seaborn library\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUtUPHzHEhD"
      },
      "source": [
        "#Boxplot to detect outliers graphically\n",
        "ax = sns.boxplot(data=num_df, orient=\"v\", palette=\"Set2\", width = 0.6, whis = 1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOLkUystzTPF"
      },
      "source": [
        "#Display boxplot for the variables with more outliers\n",
        "sns.boxplot(x=df['Temp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJr2vgnH-nBc"
      },
      "source": [
        "sns.boxplot(x=df['Rh'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_wDRlfz3y8z"
      },
      "source": [
        "Determine the ranges and Inter-Quartile Range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t8c9YJ435qo"
      },
      "source": [
        "Q1 = num_df.quantile(0.25)\n",
        "Q3 = num_df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnB__NUR5SJp"
      },
      "source": [
        "From above, it shows that there were 72 outliers since the original shape was [642, 16]. Outliers can be detected and dropped using the scikitlearn library previous to the model application. Now we are aware of the distribution of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNJGbexp4mOp"
      },
      "source": [
        "### **II. Report Dataset Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5l-RJrsEWVh"
      },
      "source": [
        "In order to obtain the summary report from temperature and humidity measurements, we have to create the dataset that contains the cumulative frequencies versus months or days. Pandas library will provide the tools to generate the final dataset before displaying it with Dash."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZHgfV-3mnNy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNUNHOOSfZj"
      },
      "source": [
        "num_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk10D8EedbyR"
      },
      "source": [
        "num_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7pvLDPOeOEL"
      },
      "source": [
        "num_df['Date'] = pd.to_datetime(num_df['Date'])\n",
        "print(num_df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9CpOnLDfQva"
      },
      "source": [
        "num_df.plot(x='Date', y = 'Temp', figsize=(18, 10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epBDqMhtftm8"
      },
      "source": [
        "num_df.plot(x='Date', y = 'Rh', figsize=(18, 10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxtJnqh7VLPl"
      },
      "source": [
        "#Separating the datetime into months, days, hours, minutes and seconds\n",
        "\n",
        "num_df['seconds'] = num_df['Date'].dt.second\n",
        "num_df['minute'] = num_df['Date'].dt.minute\n",
        "num_df['hour'] = num_df['Date'].dt.hour\n",
        "num_df['day_of_week'] = num_df['Date'].dt.weekday\n",
        "num_df['day'] = num_df['Date'].dt.day\n",
        "num_df['month'] = num_df['Date'].dt.month\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAtA48aV0SH"
      },
      "source": [
        "num_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaz6UPbIZArl"
      },
      "source": [
        "grouped_max = num_df.groupby('month').max()\n",
        "grouped_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNtshkdvatWO"
      },
      "source": [
        "grouped_max['Temp'].plot(kind = 'bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spiDh7VjS4lj"
      },
      "source": [
        "march_measures = num_df[(num_df['month']==3)]\n",
        "march_measures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZDSQP7knczn"
      },
      "source": [
        "april_measures = num_df[(num_df['month']==4)]\n",
        "april_measures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGG_MZnMrF8O"
      },
      "source": [
        "###1. Finding Max Values per Month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi-QP--EmJm_"
      },
      "source": [
        "#Maximum values of Temperature and Humidity during March and April, 2019\n",
        "\n",
        "#Max values from March\n",
        "temp_march = march_measures['Temp'] \n",
        "max_value_march = round(temp_march.max(), 2)\n",
        "print('The maximum temperature value from March 2019 was: ', max_value_march, '°C')\n",
        "\n",
        "#Max values from March\n",
        "temp_april = april_measures['Temp'] \n",
        "max_value_april = round(temp_april.max(), 2)\n",
        "print('The maximum temperature value from April 2019 was: ', max_value_april, '°C')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5IdcNRQuQ7J"
      },
      "source": [
        "###2. Finding Number of measurements expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2hDh8PEuPi1"
      },
      "source": [
        "#If we consider 5 minute increments, then there should be 12 temperature measurements captured by hour\n",
        "#24 hours each day, and then multiply it for the number of days per month\n",
        "\n",
        "exp_march = 12*24* march_measures['day'].max()\n",
        "print (\"Number of temperature captures expected in March: \", exp_march)\n",
        "\n",
        "exp_april = 12*24* april_measures['day'].max()\n",
        "print (\"Number of temperature captures expected in April: \", exp_april)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71aUf37Urbe2"
      },
      "source": [
        "###3. Total measurements captured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmwSP7QgrzIy"
      },
      "source": [
        "#Total increments in March 2019\n",
        "\n",
        "total_increments_march = len(march_measures.index)\n",
        "print('Total 5 min increments is March were: ', total_increments_march)\n",
        "\n",
        "#Total increments in April 2019\n",
        "\n",
        "total_increments_april = len(april_measures.index)\n",
        "print('Total 5 min increments is April were: ', total_increments_april)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbMRBxUhwehJ"
      },
      "source": [
        "### 4. Number of measurements over 30°C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CYYeA3Ewkmi"
      },
      "source": [
        "#For March 2019\n",
        "over_30_march =march_measures[(march_measures['Temp']>30)]\n",
        "over_30_march = len(over_30_march.index)\n",
        "print('The total number of increments over 30°C in March 2019 is: ', over_30_march)\n",
        "\n",
        "#For April 2019\n",
        "over_30_april = april_measures[(april_measures['Temp']>30)]\n",
        "over_30_april = len(over_30_april.index)\n",
        "print('The total number of increments over 30°C in March 2019 is: ', over_30_april)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZATCCvjKzeW1"
      },
      "source": [
        "### 5. Cumulative hours over 30°C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyK7WWy74w7d"
      },
      "source": [
        "#Initial dataframe for cumulative hours calculations\n",
        "num_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoZjXyP16N9U"
      },
      "source": [
        "#Moving the indexes to put the following value in the same row\n",
        "s = num_df.loc[72:2847,'Date']\n",
        "s.index = s.index - 1\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdj66t_AxXE8"
      },
      "source": [
        "num_df.insert(1, \"Following_Date\", s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaAjiWR3xtJP"
      },
      "source": [
        "num_df.loc[71:2487, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2SOd-boY2JV"
      },
      "source": [
        "#Creating a new dataset to calculate the time elapsed\n",
        "data = {\n",
        "        \"a\": (num_df['Date']),\n",
        "        \"b\": (num_df['Following_Date'])\n",
        "        \n",
        "        }\n",
        "\n",
        "time_df = pd.DataFrame(data, dtype=\"datetime64[ns]\")\n",
        "time_df[\"elapsed\"] = (time_df.b - time_df.a) / pd.Timedelta('1 hour')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDKVkP0bbo9J"
      },
      "source": [
        "time_df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIyXDbZqpFlz"
      },
      "source": [
        "e = time_df.loc[:,'elapsed']\n",
        "e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOhDSJksrkrl"
      },
      "source": [
        "num_df['Time_elapsed_in_hours'] = e\n",
        "num_df.loc[71:2487, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY38Exutr0Ie"
      },
      "source": [
        "#Finding the number of measurements in the temperature ranges and making imputations of missing values\n",
        "\n",
        "num_df['Temp'] = num_df['Temp'].fillna(0)\n",
        "num_df.Temp.isna().sum()\n",
        "\n",
        "num_df.loc[(num_df['Temp'] < 30) , 'Temp_Ranges'] = 'Under 30'\n",
        "num_df.loc[((num_df['Temp']>=30) & (num_df['Temp']<35)), 'Temp_Ranges'] = '30-35'\n",
        "num_df.loc[((num_df['Temp']>=35) & (num_df['Temp']<40)), 'Temp_Ranges'] = '35-40'\n",
        "num_df.loc[((num_df['Temp']>=40) & (num_df['Temp']<45)), 'Temp_Ranges'] = '40-45'\n",
        "num_df.loc[((num_df['Temp']>=45) & (num_df['Temp']<50)), 'Temp_Ranges'] = '45-50'\n",
        "num_df.loc[((num_df['Temp']>=50) & (num_df['Temp']<55)), 'Temp_Ranges'] = '50-55'\n",
        "num_df.loc[((num_df['Temp']>=55) & (num_df['Temp']<60)), 'Temp_Ranges'] = '55-60'\n",
        "num_df.loc[num_df['Temp']>=60, 'Temp_Ranges'] = 'Above 60'\n",
        "\n",
        "print(num_df.Temp_Ranges.value_counts())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApAHRn5I9nYB"
      },
      "source": [
        "num_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Rg1cLG9c1z"
      },
      "source": [
        "num_df.Temp_Ranges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuZtQ0-tHkoI"
      },
      "source": [
        "df2 = num_df.loc[72:2487]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aNJzqYMRDi4"
      },
      "source": [
        "df2.set_index('month')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r44_MYKY9yV"
      },
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCspJa-bVKEa"
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXgiOPM3h8J"
      },
      "source": [
        "#Finding cumulative frequencies regarding temperature ranges\n",
        "x = 0\n",
        "for i in range(1,12,1):\n",
        "  total_under_30 = []\n",
        "  total_hours_30_35 = []\n",
        "  total_hours_35_40 = []\n",
        "  total_hours_40_45 = []\n",
        "  total_hours_45_50 = []\n",
        "  total_hours_50_55 = []\n",
        "  total_hours_55_60 = []\n",
        "  total_hours_above_60 = []\n",
        "  for x in range(72, len(df2), 1):\n",
        "    if df2.at[x, 'Temp_Ranges'] == '30-35':\n",
        "      m = df2.at[x, 'Time_elapsed_in_hours']\n",
        "      total_hours_30_35.append(m)\n",
        "    elif df2.at[x, 'Temp_Ranges'] == 'Under 30':\n",
        "      n = df2.at[x, 'Time_elapsed_in_hours']\n",
        "      total_under_30.append(n)\n",
        "\n",
        "print(total_hours_30_35)\n",
        "print(total_under_30)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmOtFjx5YFuN"
      },
      "source": [
        "len(total_hours_30_35)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmuwCvnaeSiO"
      },
      "source": [
        "len(total_under_30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhkVO8FyZccm"
      },
      "source": [
        " # Iterate each element in list\n",
        "# and add them in variable total\n",
        "\n",
        "\n",
        "# Finding sum of elements in list\n",
        "total = 0\n",
        "\n",
        " \n",
        "# Iterate each element in list\n",
        "# and add them in variable total\n",
        "for ele in range(0, len(total_hours_30_35)):\n",
        "    total = total + total_hours_30_35[ele]\n",
        " \n",
        "# printing total value\n",
        "\n",
        "print(\"Cumulative hours at 30°-35°C: \", round(total, 2), \" hours.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE6cmQ63iDtd"
      },
      "source": [
        "for ele in range(0, len(total_under_30)):\n",
        "    total = total + total_under_30[ele]\n",
        "\n",
        "print(\"Cumulative hours under 30°: \", round(total, 2), \" hours.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41_61NFqr41v"
      },
      "source": [
        "###3. Final report dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJxwX2AntL0s"
      },
      "source": [
        "#Dataset structure is defined previous to the Dash displaying\n",
        "#For that, we specify the content of every column to the new transformed dataset \"final_report\"\n",
        "\n",
        "final_report = pd.DataFrame({'Months':['January','February','March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n",
        "                             'Number of Temperature Captures Registered':['NaN','NaN',total_increments_march,total_increments_april,'NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'], \n",
        "                             'Number of Temperature Captures Expected': ['NaN', 'NaN', exp_march, exp_april, 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN', 'NaN'],\n",
        "                             'Total 5 min Increments Over 30°C':['NaN','NaN',over_30_march,over_30_april,'NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             'Cumulative hours above 30° C':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '30-35':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '35-40':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '40-45':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '45-50':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '50-55':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             '55-60':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             'Above 60':['NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN'],\n",
        "                             'Maximum Temperature Observed (°C)':['NaN','NaN',max_value_march,max_value_april,'NaN','NaN','NaN','NaN','NaN','NaN','NaN','NaN']\n",
        "})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HauSyQUMzQdu"
      },
      "source": [
        "final_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqm0L2F336Av"
      },
      "source": [
        "### III. Dashboard Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Z06cth6INb"
      },
      "source": [
        "!pip install jupyter-dash -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYVieoC-xzS"
      },
      "source": [
        "!pip install dash-cytoscape -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvgO9AxWXCyp"
      },
      "source": [
        "#Installing Dash library\n",
        "!pip install dash "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHdlMTUTQrGa"
      },
      "source": [
        " !pip install Jupyterlab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDq2jyaxBrNg"
      },
      "source": [
        "#Importing libraries necessary for the task\n",
        "import dash\n",
        "from dash import no_update\n",
        "from jupyter_dash import JupyterDash  # pip install dash\n",
        "import dash_cytoscape as cyto  # pip install dash-cytoscape==0.2.0 or higher\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from jupyter_dash import JupyterDash\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import random\n",
        "import string\n",
        "import math\n",
        "from dash.dependencies import Input, Output\n",
        "import dash_table "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejm6qtPBiykk"
      },
      "source": [
        "# -------------------------------------------------------------------------------------\n",
        "# Following the final report dataset\n",
        "df = final_report\n",
        "# Creating an ID column name gives us more interactive capabilities\n",
        "df[\"id\"] = df.index +1\n",
        "print(df.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imR2v09rkvp"
      },
      "source": [
        "print (df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeMrgBq9iyDh"
      },
      "source": [
        "# App layout\n",
        "app = JupyterDash(__name__, prevent_initial_callbacks=True) # this was introduced in Dash version 1.12.0\n",
        "\n",
        "# Sorting operators (https://dash.plotly.com/datatable/filtering)\n",
        "app.layout = html.Div([\n",
        "    dash_table.DataTable(\n",
        "        id='datatable-interactivity',\n",
        "        columns=[\n",
        "            {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True, \"hideable\": True}\n",
        "            if i == \"id\" or i == \"months\"\n",
        "            else {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True}\n",
        "            for i in df.columns\n",
        "        ],\n",
        "        data=df.to_dict('records'),  # the contents of the table\n",
        "        editable=True,              # allow editing of data inside all cells\n",
        "        filter_action=\"native\",     # allow filtering of data by user ('native') or not ('none')\n",
        "        sort_action=\"native\",       # enables data to be sorted per-column by user or not ('none')\n",
        "        sort_mode=\"single\",         # sort across 'multi' or 'single' columns\n",
        "        column_selectable=\"multi\",  # allow users to select 'multi' or 'single' columns\n",
        "        row_selectable=\"multi\",     # allow users to select 'multi' or 'single' rows\n",
        "        row_deletable=True,         # choose if user can delete a row (True) or not (False)\n",
        "        selected_columns=[],        # ids of columns that user selects\n",
        "        selected_rows=[],           # indices of rows that user selects\n",
        "        page_action=\"native\",       # all data is passed to the table up-front or not ('none')\n",
        "        page_current=0,             # page number that user is on\n",
        "        page_size=12,                # number of rows visible per page\n",
        "        style_cell={                # ensure adequate header width when text is shorter than cell's text\n",
        "            'whiteSpace': 'normal',\n",
        "            'height': 'auto',\n",
        "            'lineHeight': '15px',\n",
        "\n",
        "            #'minWidth': 95, 'maxWidth': 95, 'width': 95\n",
        "        },\n",
        "        style_cell_conditional=[    # align text columns to left. By default they are aligned to right\n",
        "            {\n",
        "                'if': {'column_id': c},\n",
        "                'textAlign': 'center'\n",
        "            } for c in ['country', 'iso_alpha3']\n",
        "        ],\n",
        "        style_data={                # overflow cells' content into multiple lines\n",
        "            'whiteSpace': 'normal',\n",
        "            'height': 'auto',\n",
        "            'lineHeight': '15px'\n",
        "        }\n",
        "    ),\n",
        "\n",
        "    html.Br(),\n",
        "    html.Br(),\n",
        "    html.Div(id='bar-container'),\n",
        "    html.Div(id='choromap-container')\n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clx3MR1fjlNl"
      },
      "source": [
        "# Create bar chart\n",
        "@app.callback(\n",
        "    Output(component_id='bar-container', component_property='children'),\n",
        "    [Input(component_id='datatable-interactivity', component_property=\"derived_virtual_data\"),\n",
        "     Input(component_id='datatable-interactivity', component_property='derived_virtual_selected_rows'),\n",
        "     Input(component_id='datatable-interactivity', component_property='derived_virtual_selected_row_ids'),\n",
        "     Input(component_id='datatable-interactivity', component_property='selected_rows'),\n",
        "     Input(component_id='datatable-interactivity', component_property='derived_virtual_indices'),\n",
        "     Input(component_id='datatable-interactivity', component_property='derived_virtual_row_ids'),\n",
        "     Input(component_id='datatable-interactivity', component_property='active_cell'),\n",
        "     Input(component_id='datatable-interactivity', component_property='selected_cells')]\n",
        ")\n",
        "def update_bar(all_rows_data, slctd_row_indices, slct_rows_names, slctd_rows,\n",
        "               order_of_rows_indices, order_of_rows_names, actv_cell, slctd_cell):\n",
        "    print('***************************************************************************')\n",
        "    print('Data across all pages pre or post filtering: {}'.format(all_rows_data))\n",
        "    print('---------------------------------------------')\n",
        "    print(\"Indices of selected rows if part of table after filtering:{}\".format(slctd_row_indices))\n",
        "    print(\"Names of selected rows if part of table after filtering: {}\".format(slct_rows_names))\n",
        "    print(\"Indices of selected rows regardless of filtering results: {}\".format(slctd_rows))\n",
        "    print('---------------------------------------------')\n",
        "    print(\"Indices of all rows pre or post filtering: {}\".format(order_of_rows_indices))\n",
        "    print(\"Names of all rows pre or post filtering: {}\".format(order_of_rows_names))\n",
        "    print(\"---------------------------------------------\")\n",
        "    print(\"Complete data of active cell: {}\".format(actv_cell))\n",
        "    print(\"Complete data of all selected cells: {}\".format(slctd_cell))\n",
        "\n",
        "    dff = df if all_rows_data is None else pd.DataFrame(all_rows_data)\n",
        "\n",
        "    # used to highlight selected countries on bar chart\n",
        "    colors = ['#7FDBFF' if i in slctd_row_indices else '#0074D9'\n",
        "              for i in range(len(dff))]\n",
        "\n",
        "    if \"Number of Temperature Captures Registered\" in dff and \"Months\" in dff:\n",
        "        return [\n",
        "            dcc.Graph(id='bar-chart',\n",
        "                      figure=px.bar(\n",
        "                          data_frame=dff,\n",
        "                          x=\"Months\",\n",
        "                          y='Number of Temperature Captures Registered',\n",
        "                          labels={\"Number of Temperature Captures Registered\": \"Number of Temperature Captures Registered\"}\n",
        "                      ).update_layout(showlegend=False, xaxis={})\n",
        "                      .update_traces(marker_color=colors, hovertemplate=\"<b>%{y}</b><extra></extra>\")\n",
        "                      )\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb8fk5IOjq-r"
      },
      "source": [
        "# Create choropleth map\n",
        "@app.callback(\n",
        "    Output(component_id='choromap-container', component_property='children'),\n",
        "    [Input(component_id='datatable-interactivity', component_property=\"derived_virtual_data\"),\n",
        "     Input(component_id='datatable-interactivity', component_property='derived_virtual_selected_rows')]\n",
        ")\n",
        "def update_map(all_rows_data, slctd_row_indices):\n",
        "    dff = df if all_rows_data is None else pd.DataFrame(all_rows_data)\n",
        "\n",
        "    # highlight selected countries on map\n",
        "    borders = [5 if i in slctd_row_indices else 1\n",
        "               for i in range(len(dff))]\n",
        "\n",
        "    if \"iso_alpha3\" in dff and \"internet daily\" in dff and \"country\" in dff:\n",
        "        return [\n",
        "            dcc.Graph(id='choropleth',\n",
        "                      style={'height': 700},\n",
        "                      figure=px.choropleth(\n",
        "                          data_frame=dff,\n",
        "                          locations=\"iso_alpha3\",\n",
        "                          scope=\"africa\",\n",
        "                          color=\"internet daily\",\n",
        "                          title=\"% of hours of exposure from total hours\",\n",
        "                          template='plotly_dark',\n",
        "                          hover_data=['country', 'internet daily'],\n",
        "                      ).update_layout(showlegend=False, title=dict(font=dict(size=28), x=0.5, xanchor='center'))\n",
        "                      .update_traces(marker_line_width=borders, hovertemplate=\"<b>%{customdata[0]}</b><br><br>\" +\n",
        "                                                                              \"%{customdata[1]}\" + \"%\")\n",
        "                      )\n",
        "        ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kLUpzmCjv0j"
      },
      "source": [
        "# Highlight selected column\n",
        "@app.callback(\n",
        "    Output('datatable-interactivity', 'style_data_conditional'),\n",
        "    [Input('datatable-interactivity', 'selected_columns')]\n",
        ")\n",
        "def update_styles(selected_columns):\n",
        "    return [{\n",
        "        'if': {'column_id': i},\n",
        "        'background_color': '#D2F3FF'\n",
        "    } for i in selected_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgy3a1R_bgxb"
      },
      "source": [
        "app.run_server(mode='external', port=8051)\n",
        "\n",
        "#import os\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #app.css.config.serve_locally = True\n",
        "    #app.scripts.config.serve_locally = True\n",
        "    #app.run_server(debug=True, use_reloader=False, host=os.getenv('HOST', '127.0.0.1'),port=os.getenv('PORT', '8051'), proxy= None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FImNBn5738O"
      },
      "source": [
        "\n",
        "### IV. Predictive Models Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzWQ59VW8BFT"
      },
      "source": [
        "For the predictive model, we will use temperature, humidity, light, pressure, shock, location, time of exposure, maximum temperature, and speed to predict at what stTemp_Ranges of the route temperature excursions will happen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si2uDmh4rRcQ"
      },
      "source": [
        "#Importing libraries\n",
        "import numpy as np # used for handling numbers\n",
        "import pandas as pd # used for handling the dataset\n",
        "from sklearn.impute import SimpleImputer # used for handling missing data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
        "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
        "from sklearn.preprocessing import StandardScaler # used for feature scaling"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}